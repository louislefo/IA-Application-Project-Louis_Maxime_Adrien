{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Football Player Analysis - Machine Learning\n",
        "\n",
        "This notebook loads the dataset, processes features, and trains two models:\n",
        "1. **Linear Regression**: To predict the current `overall_rating`.\n",
        "2. **Logistic Regression**: To classify the player's future development (`future_class`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, classification_report\n",
        "\n",
        "# Set plot style for better aesthetics\n",
        "sns.set(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading\n",
        "\n",
        "We define the path to the dataset relative to this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Determine the project root directory (assuming notebook is in src/)\n",
        "PROJECT_ROOT = os.path.abspath(\"..\")\n",
        "DATA_PATH = os.path.join(PROJECT_ROOT, \"data\", \"fifa_players.csv\")\n",
        "\n",
        "print(f\"Loading data from: {DATA_PATH}\")\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    print(\"Data loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {DATA_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Data Preview ===\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"\\n=== Column Info ===\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Feature Selection and Cleaning\n",
        "\n",
        "We select specific physical and technical attributes to use as features for our models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define targets and features\n",
        "target_overall = \"overall_rating\"\n",
        "target_potential = \"potential\"\n",
        "col_age = \"age\"\n",
        "\n",
        "feature_cols = [\n",
        "    \"age\",\n",
        "    \"height_cm\",\n",
        "    \"weight_kgs\",\n",
        "    \"finishing\",\n",
        "    \"dribbling\",\n",
        "    \"short_passing\",\n",
        "    \"acceleration\",\n",
        "    \"sprint_speed\",\n",
        "    \"stamina\",\n",
        "    \"strength\",\n",
        "]\n",
        "\n",
        "# Check if all columns exist\n",
        "missing_cols = [c for c in feature_cols + [target_overall, target_potential, col_age] if c not in df.columns]\n",
        "if missing_cols:\n",
        "    raise ValueError(f\"Missing columns in CSV: {missing_cols}\")\n",
        "\n",
        "# Drop rows with missing values in selected columns\n",
        "df_clean = df.dropna(subset=feature_cols + [target_overall, target_potential, col_age]).copy()\n",
        "\n",
        "print(f\"Number of players after cleaning: {len(df_clean)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Regression Model: Predicting `overall_rating`\n",
        "\n",
        "We use Linear Regression to estimate a player's current overall rating based on their attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df_clean[feature_cols]\n",
        "y = df_clean[target_overall]\n",
        "\n",
        "# Split data (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "reg_model = LinearRegression()\n",
        "reg_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = reg_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"=== Regression Model Results (overall_rating) ===\")\n",
        "print(f\"MSE : {mse:.2f}\")\n",
        "print(f\"RÂ²  : {r2:.3f}\")\n",
        "\n",
        "print(\"\\nCoefficients (Impact of each feature):\")\n",
        "print(f\"Intercept : {reg_model.intercept_:.3f}\")\n",
        "for feat, coef in zip(feature_cols, reg_model.coef_):\n",
        "    print(f\"{feat:15s} -> {coef:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualization: True vs Predicted Ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.3, color='blue')\n",
        "plt.xlabel(\"True Ratings (overall_rating)\")\n",
        "plt.ylabel(\"Predicted Ratings\")\n",
        "plt.title(\"Regression: True vs Predicted (overall_rating)\")\n",
        "\n",
        "# Plot perfect prediction line\n",
        "min_val = min(y_test.min(), y_pred.min())\n",
        "max_val = max(y_test.max(), y_pred.max())\n",
        "plt.plot([min_val, max_val], [min_val, max_val], \"r--\", lw=2)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Classification Model: Predicting Future Development\n",
        "\n",
        "We create a new target variable `future_class` based on the gap between `potential` and `overall_rating`, and the player's `age`.\n",
        "\n",
        "**Rules:**\n",
        "- `high_growth`: gap >= 10 and age <= 23\n",
        "- `likely_improve`: gap >= 4\n",
        "- `stable`: -2 <= gap < 4\n",
        "- `decline`: otherwise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_future_label(row):\n",
        "    \"\"\"\n",
        "    Creates a 'future_class' label based on potential, overall_rating, and age.\n",
        "    \"\"\"\n",
        "    overall = row[\"overall_rating\"]\n",
        "    potential = row[\"potential\"]\n",
        "    age = row[\"age\"]\n",
        "\n",
        "    gap = potential - overall\n",
        "\n",
        "    if gap >= 10 and age <= 23:\n",
        "        return \"high_growth\"\n",
        "    elif gap >= 4:\n",
        "        return \"likely_improve\"\n",
        "    elif gap >= -2:\n",
        "        return \"stable\"\n",
        "    else:\n",
        "        return \"decline\"\n",
        "\n",
        "# Apply the function\n",
        "df_clean[\"future_class\"] = df_clean.apply(build_future_label, axis=1)\n",
        "\n",
        "print(\"Future Class Distribution:\")\n",
        "print(df_clean[\"future_class\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_cls = df_clean[feature_cols]\n",
        "y_cls = df_clean[\"future_class\"]\n",
        "\n",
        "# Stratified split to maintain class balance\n",
        "Xc_train, Xc_test, yc_train, yc_test = train_test_split(\n",
        "    X_cls, y_cls, test_size=0.2, random_state=42, stratify=y_cls\n",
        ")\n",
        "\n",
        "# Train Logistic Regression\n",
        "clf = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    multi_class=\"multinomial\"\n",
        ")\n",
        "clf.fit(Xc_train, yc_train)\n",
        "\n",
        "# Predict\n",
        "yc_pred = clf.predict(Xc_test)\n",
        "\n",
        "print(\"=== Classification Model Results (future_class) ===\")\n",
        "print(classification_report(yc_test, yc_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Example Prediction\n",
        "\n",
        "We create a synthetic player to test our models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example_player = {\n",
        "    \"age\": 20,\n",
        "    \"height_cm\": 175.0,\n",
        "    \"weight_kgs\": 70.0,\n",
        "    \"finishing\": 78,\n",
        "    \"dribbling\": 85,\n",
        "    \"short_passing\": 82,\n",
        "    \"acceleration\": 88,\n",
        "    \"sprint_speed\": 90,\n",
        "    \"stamina\": 80,\n",
        "    \"strength\": 65,\n",
        "}\n",
        "\n",
        "example_df = pd.DataFrame([example_player])\n",
        "\n",
        "# Predict using both models\n",
        "overall_pred_example = reg_model.predict(example_df[feature_cols])[0]\n",
        "future_class_example = clf.predict(example_df[feature_cols])[0]\n",
        "future_proba_example = clf.predict_proba(example_df[feature_cols])[0]\n",
        "classes = clf.classes_\n",
        "\n",
        "print(\"=== Example Player Analysis ===\")\n",
        "print(\"Player Stats:\")\n",
        "for k, v in example_player.items():\n",
        "    print(f\"  {k:15s} = {v}\")\n",
        "\n",
        "print(f\"\\nPredicted Overall Rating: {overall_pred_example:.1f}\")\n",
        "print(f\"Predicted Future Class:   {future_class_example}\")\n",
        "print(\"Class Probabilities:\")\n",
        "for cls, proba in zip(classes, future_proba_example):\n",
        "    print(f\"  {cls:15s} -> {proba:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
