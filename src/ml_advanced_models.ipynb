{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd82b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, classification_report, confusion_matrix, accuracy_score\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úì Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b65cf28",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9661e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT, \"data\", \"fifa_players.csv\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "\n",
    "# Define features and targets\n",
    "target_overall = \"overall_rating\"\n",
    "target_potential = \"potential\"\n",
    "\n",
    "feature_cols = [\n",
    "    \"age\", \"height_cm\", \"weight_kgs\",\n",
    "    \"finishing\", \"dribbling\", \"short_passing\",\n",
    "    \"acceleration\", \"sprint_speed\", \"stamina\", \"strength\"\n",
    "]\n",
    "\n",
    "# Clean data\n",
    "df_clean = df.dropna(subset=feature_cols + [target_overall, target_potential]).copy()\n",
    "\n",
    "# Prepare datasets\n",
    "X = df_clean[feature_cols].copy()\n",
    "y_overall = df_clean[target_overall].copy()\n",
    "\n",
    "# Create future_class for classification\n",
    "def build_future_label(row):\n",
    "    gap = row[target_potential] - row[target_overall]\n",
    "    age = row[\"age\"]\n",
    "    if gap >= 10 and age <= 23:\n",
    "        return \"high_growth\"\n",
    "    elif gap >= 4:\n",
    "        return \"likely_improve\"\n",
    "    elif gap >= -2:\n",
    "        return \"stable\"\n",
    "    else:\n",
    "        return \"decline\"\n",
    "\n",
    "df_clean[\"future_class\"] = df_clean.apply(build_future_label, axis=1)\n",
    "y_future = df_clean[\"future_class\"].copy()\n",
    "\n",
    "print(f\"‚úì Data loaded: {len(df_clean)} players\")\n",
    "print(f\"‚úì Features: {feature_cols}\")\n",
    "print(f\"‚úì Target (Regression): {target_overall}\")\n",
    "print(f\"‚úì Target (Classification): future_class\")\n",
    "print(f\"\\nClass Distribution:\\n{y_future.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f1607a",
   "metadata": {},
   "source": [
    "## 2. Regression Models: Predicting Overall Rating\n",
    "\n",
    "### 2.1 Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a058695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_overall, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"‚úì Training set: {len(X_train)} samples\")\n",
    "print(f\"‚úì Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d810467",
   "metadata": {},
   "source": [
    "### 2.2 Model Training - Linear Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b527f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "lr_mse = mean_squared_error(y_test, y_pred_lr)\n",
    "lr_rmse = np.sqrt(lr_mse)\n",
    "lr_mae = mean_absolute_error(y_test, y_pred_lr)\n",
    "lr_r2 = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# Cross-validation\n",
    "lr_cv_scores = cross_val_score(lr_model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"LINEAR REGRESSION (Baseline)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MSE:  {lr_mse:.4f}\")\n",
    "print(f\"RMSE: {lr_rmse:.4f}\")\n",
    "print(f\"MAE:  {lr_mae:.4f}\")\n",
    "print(f\"R¬≤:   {lr_r2:.4f}\")\n",
    "print(f\"CV R¬≤ (mean ¬± std): {lr_cv_scores.mean():.4f} ¬± {lr_cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2975d9",
   "metadata": {},
   "source": [
    "### 2.3 Model Training - Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "rf_mse = mean_squared_error(y_test, y_pred_rf)\n",
    "rf_rmse = np.sqrt(rf_mse)\n",
    "rf_mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "rf_r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Cross-validation\n",
    "rf_cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"RANDOM FOREST REGRESSOR\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MSE:  {rf_mse:.4f}\")\n",
    "print(f\"RMSE: {rf_rmse:.4f}\")\n",
    "print(f\"MAE:  {rf_mae:.4f}\")\n",
    "print(f\"R¬≤:   {rf_r2:.4f}\")\n",
    "print(f\"CV R¬≤ (mean ¬± std): {rf_cv_scores.mean():.4f} ¬± {rf_cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d9ef7",
   "metadata": {},
   "source": [
    "### 2.4 Model Training - Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85220e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Regressor\n",
    "gb_model = GradientBoostingRegressor(\n",
    "    n_estimators=100, \n",
    "    learning_rate=0.1, \n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "gb_mse = mean_squared_error(y_test, y_pred_gb)\n",
    "gb_rmse = np.sqrt(gb_mse)\n",
    "gb_mae = mean_absolute_error(y_test, y_pred_gb)\n",
    "gb_r2 = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "# Cross-validation\n",
    "gb_cv_scores = cross_val_score(gb_model, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"GRADIENT BOOSTING REGRESSOR\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MSE:  {gb_mse:.4f}\")\n",
    "print(f\"RMSE: {gb_rmse:.4f}\")\n",
    "print(f\"MAE:  {gb_mae:.4f}\")\n",
    "print(f\"R¬≤:   {gb_r2:.4f}\")\n",
    "print(f\"CV R¬≤ (mean ¬± std): {gb_cv_scores.mean():.4f} ¬± {gb_cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ec3e0",
   "metadata": {},
   "source": [
    "### 2.5 Model Training - XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d25fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "xgb_mse = mean_squared_error(y_test, y_pred_xgb)\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "xgb_mae = mean_absolute_error(y_test, y_pred_xgb)\n",
    "xgb_r2 = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Cross-validation\n",
    "xgb_cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"XGBOOST REGRESSOR\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MSE:  {xgb_mse:.4f}\")\n",
    "print(f\"RMSE: {xgb_rmse:.4f}\")\n",
    "print(f\"MAE:  {xgb_mae:.4f}\")\n",
    "print(f\"R¬≤:   {xgb_r2:.4f}\")\n",
    "print(f\"CV R¬≤ (mean ¬± std): {xgb_cv_scores.mean():.4f} ¬± {xgb_cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048d12fd",
   "metadata": {},
   "source": [
    "## 3. Regression Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8661a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "regression_results = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Random Forest', 'Gradient Boosting', 'XGBoost'],\n",
    "    'MSE': [lr_mse, rf_mse, gb_mse, xgb_mse],\n",
    "    'RMSE': [lr_rmse, rf_rmse, gb_rmse, xgb_rmse],\n",
    "    'MAE': [lr_mae, rf_mae, gb_mae, xgb_mae],\n",
    "    'R¬≤ (Test)': [lr_r2, rf_r2, gb_r2, xgb_r2],\n",
    "    'R¬≤ (CV Mean)': [lr_cv_scores.mean(), rf_cv_scores.mean(), gb_cv_scores.mean(), xgb_cv_scores.mean()]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"REGRESSION MODELS COMPARISON - PREDICTING OVERALL RATING\")\n",
    "print(\"=\" * 80)\n",
    "print(regression_results.to_string(index=False))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Find best model\n",
    "best_model_idx = regression_results['R¬≤ (Test)'].idxmax()\n",
    "best_model_name = regression_results.loc[best_model_idx, 'Model']\n",
    "best_r2 = regression_results.loc[best_model_idx, 'R¬≤ (Test)']\n",
    "\n",
    "print(f\"\\nüèÜ BEST REGRESSION MODEL: {best_model_name} (R¬≤ = {best_r2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a2cfe6",
   "metadata": {},
   "source": [
    "### 3.1 Visualization: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot R¬≤ Comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# R¬≤ Comparison\n",
    "axes[0].barh(regression_results['Model'], regression_results['R¬≤ (Test)'], color='steelblue')\n",
    "axes[0].set_xlabel('R¬≤ Score (Test Set)', fontsize=12)\n",
    "axes[0].set_title('Regression Models - R¬≤ Performance', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlim([0, 1])\n",
    "for i, v in enumerate(regression_results['R¬≤ (Test)']):\n",
    "    axes[0].text(v + 0.02, i, f'{v:.4f}', va='center', fontweight='bold')\n",
    "\n",
    "# RMSE Comparison\n",
    "axes[1].barh(regression_results['Model'], regression_results['RMSE'], color='coral')\n",
    "axes[1].set_xlabel('RMSE (Lower is Better)', fontsize=12)\n",
    "axes[1].set_title('Regression Models - RMSE Performance', fontsize=14, fontweight='bold')\n",
    "for i, v in enumerate(regression_results['RMSE']):\n",
    "    axes[1].text(v + 0.5, i, f'{v:.2f}', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PROJECT_ROOT, 'src', 'regression_models_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Chart saved: regression_models_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e310b15",
   "metadata": {},
   "source": [
    "### 3.2 Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a284f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance from ensemble models\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "feature_importance_gb = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': gb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "feature_importance_xgb = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FEATURE IMPORTANCE - RANDOM FOREST\")\n",
    "print(\"=\" * 50)\n",
    "print(feature_importance_rf.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FEATURE IMPORTANCE - GRADIENT BOOSTING\")\n",
    "print(\"=\" * 50)\n",
    "print(feature_importance_gb.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FEATURE IMPORTANCE - XGBOOST\")\n",
    "print(\"=\" * 50)\n",
    "print(feature_importance_xgb.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1e8b60",
   "metadata": {},
   "source": [
    "### 3.3 Visualization: Feature Importance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38161844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "models_importance = [\n",
    "    (feature_importance_rf, 'Random Forest', axes[0]),\n",
    "    (feature_importance_gb, 'Gradient Boosting', axes[1]),\n",
    "    (feature_importance_xgb, 'XGBoost', axes[2])\n",
    "]\n",
    "\n",
    "for importance_df, model_name, ax in models_importance:\n",
    "    ax.barh(importance_df['Feature'], importance_df['Importance'], color='teal')\n",
    "    ax.set_xlabel('Importance Score', fontsize=11)\n",
    "    ax.set_title(f'{model_name}\\nFeature Importance', fontsize=12, fontweight='bold')\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PROJECT_ROOT, 'src', 'feature_importance_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Chart saved: feature_importance_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e464e",
   "metadata": {},
   "source": [
    "## 4. Classification Models: Predicting Future Development\n",
    "\n",
    "### 4.1 Train/Test Split for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ef565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split for classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(\n",
    "    X, y_future, test_size=0.2, random_state=42, stratify=y_future\n",
    ")\n",
    "\n",
    "print(f\"‚úì Classification Training set: {len(X_train_cls)} samples\")\n",
    "print(f\"‚úì Classification Test set: {len(X_test_cls)} samples\")\n",
    "print(f\"\\nClass Distribution (Train):\\n{y_train_cls.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1188c6a0",
   "metadata": {},
   "source": [
    "### 4.2 Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47274500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression (baseline)\n",
    "lr_clf = LogisticRegression(max_iter=1000, multi_class='multinomial', random_state=42)\n",
    "lr_clf.fit(X_train_cls, y_train_cls)\n",
    "y_pred_lr_cls = lr_clf.predict(X_test_cls)\n",
    "\n",
    "lr_cls_accuracy = accuracy_score(y_test_cls, y_pred_lr_cls)\n",
    "lr_cls_cv = cross_val_score(lr_clf, X_train_cls, y_train_cls, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"LOGISTIC REGRESSION CLASSIFIER\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Accuracy: {lr_cls_accuracy:.4f}\")\n",
    "print(f\"CV Accuracy (mean ¬± std): {lr_cls_cv.mean():.4f} ¬± {lr_cls_cv.std():.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_cls, y_pred_lr_cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d7d7bd",
   "metadata": {},
   "source": [
    "### 4.3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae222ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_clf.fit(X_train_cls, y_train_cls)\n",
    "y_pred_rf_cls = rf_clf.predict(X_test_cls)\n",
    "\n",
    "rf_cls_accuracy = accuracy_score(y_test_cls, y_pred_rf_cls)\n",
    "rf_cls_cv = cross_val_score(rf_clf, X_train_cls, y_train_cls, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"RANDOM FOREST CLASSIFIER\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Accuracy: {rf_cls_accuracy:.4f}\")\n",
    "print(f\"CV Accuracy (mean ¬± std): {rf_cls_cv.mean():.4f} ¬± {rf_cls_cv.std():.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_cls, y_pred_rf_cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998d8c03",
   "metadata": {},
   "source": [
    "### 4.4 Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed53b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "gb_clf.fit(X_train_cls, y_train_cls)\n",
    "y_pred_gb_cls = gb_clf.predict(X_test_cls)\n",
    "\n",
    "gb_cls_accuracy = accuracy_score(y_test_cls, y_pred_gb_cls)\n",
    "gb_cls_cv = cross_val_score(gb_clf, X_train_cls, y_train_cls, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"GRADIENT BOOSTING CLASSIFIER\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Accuracy: {gb_cls_accuracy:.4f}\")\n",
    "print(f\"CV Accuracy (mean ¬± std): {gb_cls_cv.mean():.4f} ¬± {gb_cls_cv.std():.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_cls, y_pred_gb_cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f9ff06",
   "metadata": {},
   "source": [
    "### 4.5 XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62141ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Classifier\n",
    "# Encode target classes\n",
    "le = LabelEncoder()\n",
    "y_train_cls_encoded = le.fit_transform(y_train_cls)\n",
    "y_test_cls_encoded = le.transform(y_test_cls)\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_clf.fit(X_train_cls, y_train_cls_encoded)\n",
    "y_pred_xgb_cls = xgb_clf.predict(X_test_cls)\n",
    "\n",
    "# Map back to original labels\n",
    "y_pred_xgb_cls = le.inverse_transform(y_pred_xgb_cls)\n",
    "\n",
    "xgb_cls_accuracy = accuracy_score(y_test_cls, y_pred_xgb_cls)\n",
    "xgb_cls_cv = cross_val_score(xgb_clf, X_train_cls, y_train_cls_encoded, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"XGBOOST CLASSIFIER\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Accuracy: {xgb_cls_accuracy:.4f}\")\n",
    "print(f\"CV Accuracy (mean ¬± std): {xgb_cls_cv.mean():.4f} ¬± {xgb_cls_cv.std():.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_cls, y_pred_xgb_cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c513cd2b",
   "metadata": {},
   "source": [
    "## 5. Classification Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab5972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "classification_results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'Gradient Boosting', 'XGBoost'],\n",
    "    'Accuracy (Test)': [lr_cls_accuracy, rf_cls_accuracy, gb_cls_accuracy, xgb_cls_accuracy],\n",
    "    'CV Accuracy (Mean)': [lr_cls_cv.mean(), rf_cls_cv.mean(), gb_cls_cv.mean(), xgb_cls_cv.mean()],\n",
    "    'CV Std': [lr_cls_cv.std(), rf_cls_cv.std(), gb_cls_cv.std(), xgb_cls_cv.std()]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CLASSIFICATION MODELS COMPARISON - PREDICTING FUTURE DEVELOPMENT\")\n",
    "print(\"=\" * 80)\n",
    "print(classification_results.to_string(index=False))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Find best model\n",
    "best_cls_idx = classification_results['Accuracy (Test)'].idxmax()\n",
    "best_cls_name = classification_results.loc[best_cls_idx, 'Model']\n",
    "best_cls_acc = classification_results.loc[best_cls_idx, 'Accuracy (Test)']\n",
    "\n",
    "print(f\"\\nüèÜ BEST CLASSIFICATION MODEL: {best_cls_name} (Accuracy = {best_cls_acc:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25c6b82",
   "metadata": {},
   "source": [
    "### 5.1 Visualization: Classification Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c22e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy Comparison\n",
    "axes[0].barh(classification_results['Model'], classification_results['Accuracy (Test)'], color='steelblue')\n",
    "axes[0].set_xlabel('Accuracy Score (Test Set)', fontsize=12)\n",
    "axes[0].set_title('Classification Models - Accuracy Performance', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlim([0, 1])\n",
    "for i, v in enumerate(classification_results['Accuracy (Test)']):\n",
    "    axes[0].text(v + 0.02, i, f'{v:.4f}', va='center', fontweight='bold')\n",
    "\n",
    "# CV Accuracy Comparison\n",
    "axes[1].bar(range(len(classification_results)), classification_results['CV Accuracy (Mean)'], \n",
    "            yerr=classification_results['CV Std'], capsize=5, color='coral', alpha=0.7)\n",
    "axes[1].set_xticks(range(len(classification_results)))\n",
    "axes[1].set_xticklabels(classification_results['Model'], rotation=45, ha='right')\n",
    "axes[1].set_ylabel('CV Accuracy', fontsize=12)\n",
    "axes[1].set_title('Classification Models - Cross-Validation Performance', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PROJECT_ROOT, 'src', 'classification_models_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Chart saved: classification_models_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739df12b",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning (Optional - Best Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for the best regression model (let's use XGBoost)\n",
    "print(\"üîß Hyperparameter Tuning for XGBoost Regressor...\")\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [50, 100, 150]\n",
    "}\n",
    "\n",
    "xgb_tuned = xgb.XGBRegressor(random_state=42, n_jobs=-1)\n",
    "grid_search = GridSearchCV(xgb_tuned, param_grid_xgb, cv=3, scoring='r2', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"‚úì Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"‚úì Best CV R¬≤ Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate tuned model\n",
    "xgb_tuned_best = grid_search.best_estimator_\n",
    "y_pred_xgb_tuned = xgb_tuned_best.predict(X_test)\n",
    "xgb_tuned_r2 = r2_score(y_test, y_pred_xgb_tuned)\n",
    "xgb_tuned_rmse = np.sqrt(mean_squared_error(y_test, y_pred_xgb_tuned))\n",
    "\n",
    "print(f\"\\nTuned XGBoost Performance:\")\n",
    "print(f\"  R¬≤ (Test): {xgb_tuned_r2:.4f}\")\n",
    "print(f\"  RMSE: {xgb_tuned_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3c1201",
   "metadata": {},
   "source": [
    "## 7. Summary & Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ce644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 1 SUMMARY - ADVANCED ML MODELS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä REGRESSION ANALYSIS (Predicting Overall Rating):\")\n",
    "print(f\"  ‚Ä¢ Best Model: {best_model_name}\")\n",
    "print(f\"  ‚Ä¢ R¬≤ Score: {best_r2:.4f}\")\n",
    "print(f\"  ‚Ä¢ Most Important Features:\")\n",
    "if best_model_name == 'Random Forest':\n",
    "    for idx, row in feature_importance_rf.head(3).iterrows():\n",
    "        print(f\"    - {row['Feature']}: {row['Importance']:.4f}\")\n",
    "elif best_model_name == 'XGBoost':\n",
    "    for idx, row in feature_importance_xgb.head(3).iterrows():\n",
    "        print(f\"    - {row['Feature']}: {row['Importance']:.4f}\")\n",
    "else:\n",
    "    for idx, row in feature_importance_gb.head(3).iterrows():\n",
    "        print(f\"    - {row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "print(\"\\nüéØ CLASSIFICATION ANALYSIS (Predicting Future Development):\")\n",
    "print(f\"  ‚Ä¢ Best Model: {best_cls_name}\")\n",
    "print(f\"  ‚Ä¢ Accuracy: {best_cls_acc:.4f}\")\n",
    "print(f\"  ‚Ä¢ Classes Predicted:\")\n",
    "for cls in y_future.unique():\n",
    "    count = (y_test_cls == cls).sum()\n",
    "    print(f\"    - {cls}: {count} players\")\n",
    "\n",
    "print(\"\\n‚úÖ Phase 1 Completed Successfully!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
